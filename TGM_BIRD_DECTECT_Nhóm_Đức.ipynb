{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TGM_BIRD_DECTECT.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOR+/G9qjKthTyg5kdXWXB4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kusanagi242/BTVN/blob/main/TGM_BIRD_DECTECT_Nh%C3%B3m_%C4%90%E1%BB%A9c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6G-zxIWNtp7"
      },
      "source": [
        "#Trần Minh Đức - 18146105\n",
        "#Nguyễn Trần Toàn Phú - 18146189\n",
        "#Phan Xuân Lộc - 18146171"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPjRjo417hjl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive') #Connect to google drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61lUO3yC8FZO"
      },
      "source": [
        "!ls gdrive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzj_PUum4d8I"
      },
      "source": [
        "!ls gdrive/MyDrive/images/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAzQ-1Qv8Zzg"
      },
      "source": [
        "#preparing libary\n",
        "import numpy as np\n",
        "import functools\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "train_root = Path('gdrive/MyDrive/images/') #Tạo đường dẫn "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf93dllyAYMi"
      },
      "source": [
        "#Khởi tạo các thông số cơ bản cho data đầu vào\n",
        "batch_size = 18\n",
        "img_height = 224 #Resize lại các ảnh data đầu vào\n",
        "img_width = 224   #Resize lại các ảnh data đầu vào\n",
        "\n",
        "#Tạo tập Training\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_root, #đường dẫn đầu vào\n",
        "    validation_split=0.2, #Use 80% data to training\n",
        "    subset=\"training\",\n",
        "    seed = 123,\n",
        "    image_size = (img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUWdex4ftJvj"
      },
      "source": [
        "#Tạp tập Validation\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_root,\n",
        "    validation_split=0.2, #Use 20% data to validation\n",
        "    subset=\"validation\",\n",
        "    seed = 123,\n",
        "    image_size = (img_height,img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7ckWrLuBIYZ"
      },
      "source": [
        "#create matrix\n",
        "a = np.eye(200)\n",
        "#create dataset\n",
        "filelist_ds = tf.data.Dataset.list_files(str(train_root/'*/*'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIiQE6HxFoAY"
      },
      "source": [
        "#Tạo Label cho các file\n",
        "def get_label(file_path):\n",
        "  for item in train_root.glob(\"*\"):\n",
        "    if item.name[0] == '0': #0xx\n",
        "      if item.name[1]== '0': #00x\n",
        "        i = item.name[2],     # i =x\n",
        "        i = functools.reduce(lambda sub, ele: sub * 10 + ele, i) # change tuple to str\n",
        "        i = int(i)-1 #change str to int  #Do giá trị đầu tiên của ma trận là 0 nên giá trị đầu của tệp là 1 -1 để về đúng ma trận 0 \n",
        "        labels = a[i]\n",
        "      else: #0ab with a 0->9  \n",
        "        i = item.name[1] + item.name[2], \n",
        "        i = functools.reduce(lambda sub, ele: sub * 10 + ele, i)\n",
        "        i = int(i)-1\n",
        "        labels = a[i]\n",
        "    if item.name[0] == '1': #1xx\n",
        "      if item.name[1] == '0': #10x\n",
        "        i = str(1) +str(0)+ item.name[2],\n",
        "        i = functools.reduce(lambda sub, ele: sub * 10 + ele, i)\n",
        "        i = int(i)-1\n",
        "        labels = a[i]\n",
        "      else: #1ab with a 0->9\n",
        "        i = str(1) + item.name[1] + item.name[2],\n",
        "        i = functools.reduce(lambda sub, ele: sub * 10 + ele, i) \n",
        "        i = int(i)-1\n",
        "        labels = a[i]\n",
        "    if item.name[0]=='2': #2xx\n",
        "      if item.name[1] == '0':\n",
        "        i = str(2) +str(0)+ item.name[2],\n",
        "        i = functools.reduce(lambda sub, ele: sub * 10 + ele, i)\n",
        "        i = int(i)-1\n",
        "        labels = a[i]\n",
        "  return tf.convert_to_tensor(labels) #Error: Chưa xác định được "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdN3y_qvsR0P"
      },
      "source": [
        "def preprocessing(file_path):\n",
        "  # read file\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = tf.image.decode_jpeg(img, channels=3) #channels =3 --> ảnh màu, 1--> xám\n",
        "  # transform\n",
        "  # convert from uint8 to float32 and normalize values to [0, 1]\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize image\n",
        "  img = tf.image.resize(img, [img_width, img_height])\n",
        "  # .......\n",
        "  # get image label\n",
        "  label = get_label(file_path)\n",
        "\n",
        "  # return\n",
        "  return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owNAonvIDQ4f"
      },
      "source": [
        "ds_size = 6027\n",
        "batch_size = 18\n",
        "# Build dataset\n",
        "train_ds = filelist_ds.shuffle(ds_size)\n",
        "train_ds = train_ds.map(preprocessing, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "train_ds = train_ds.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe6SfAOfDq-Q"
      },
      "source": [
        "#create model with Sequential API\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=(224,224,3))) #Input Values\n",
        "#1 ///////////////////////////////////////////////////////\n",
        "model.add(layers.Conv2D(64,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.Conv2D(64,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "#2 ///////////////////////////////////////////////////////\n",
        "model.add(layers.Conv2D(128,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.Conv2D(128,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "#3 ///////////////////////////////////////////////////////\n",
        "model.add(layers.Conv2D(256,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.Conv2D(256,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.Conv2D(256,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "#4 ///////////////////////////////////////////////////////\n",
        "model.add(layers.Conv2D(512,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.Conv2D(512,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.Conv2D(512,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "#5 ///////////////////////////////////////////////////////\n",
        "model.add(layers.Conv2D(512,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.Conv2D(512,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.Conv2D(512,3,strides=(1,1),padding= 'same', activation='relu'))\n",
        "model.add(layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "#model.add(layers.Dropout(1))\n",
        "model.add(layers.Dense(4096, activation='relu'))\n",
        "#model.add(layers.Dropout(1))\n",
        "model.add(layers.Dense(200, activation='softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6T-OQkKkr-C"
      },
      "source": [
        "model.summary() #Xem thong tin cac lop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjjP6U1kpvhJ"
      },
      "source": [
        "(X_train,Y_train),(X_test,Y_test) = mnist.load_data()\n",
        "#print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEbQQ3R-piIv"
      },
      "source": [
        "#reshape and normalize\n",
        "X_train = X_train.reshape((X_train.shape[0],28,28,1)).astype('float32')/255 #Chuyển biến số nguyên thành số thực để normalize\n",
        "X_test = X_test.reshape((X_test.shape[0],28,28,1)).astype('float32')/255\n",
        "\n",
        "Y_train = to_categorical(Y_train,200)\n",
        "Y_test = to_categorical(Y_test,200)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCRamLBRFja9"
      },
      "source": [
        "# Compile model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORkJ8a9CFweF"
      },
      "source": [
        "# Train model\n",
        "model.fit(train_ds, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSP7a_aVBq79"
      },
      "source": [
        "model.save('gdrive/MyDrive/Model_Trained/BirdTrained.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}